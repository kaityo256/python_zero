<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>

<style>
    .btn-square {
      display: inline-block;
      padding: 0.5em 0.5em;
      text-decoration: none;
      background: #668ad8;
      color: #FFF;
      border-bottom: solid 4px #626295;
      border-radius: 5px;
    }

    .btn-square:active {
      -webkit-transform: translateY(4px);
      transform: translateY(4px);
      border-bottom: none;
    }
  .markdown-body {
    box-sizing: border-box;
    min-width: 200px;
    max-width: 980px;
    margin: 0 auto;
    padding: 45px;
  }
  p.caption{
    display:none;
  }
  img {width: 100%}

  @media (max-width: 767px) {
    .markdown-body {
      padding: 15px;
    }
  }
</style>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://kaityo256.github.io/python_zero/github-markdown.css" type="text/css" />
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
<link href="https://use.fontawesome.com/releases/v5.6.1/css/all.css" rel="stylesheet">
</head>
<body>
<article class="markdown-body">
<h1 id="簡単な機械学習">簡単な機械学習</h1>
<p><a href="../index.html">[Up]</a> <a href="https://github.com/kaityo256/python_zero">[Repository]</a></p>
<h2 id="本講で学ぶこと">本講で学ぶこと</h2>
<ul>
<li>機械学習の概要</li>
<li>回帰</li>
<li>GAN</li>
</ul>
<h2 id="機械学習の概要">機械学習の概要</h2>
<p>昨今、「機械学習」「ディープラーニング」「AI」といった言葉をよく聞く。「TensorFlow」など、広く使われている機械学習のフレームワークの多くがPythonで記述されていることもあり、機械学習をする上でPythonが事実上の共通語になりつつある。機械学習による派手な結果を目にすることも多いだろう。せっかく本講義でPythonを学んだのであるから、最後は機械学習を体験してみよう。今回は、ざっと機械学習の概要について触れてから、機械学習で注目されている技術の一つ、GANによる画像生成を体験してみる。</p>
<h3 id="機械学習の種類">機械学習の種類</h3>
<p>一口に「機械学習」と言っても、機械学習がカバーする範囲は広い。現在も様々な技術が提案されているため、その全てを厳密に分類するのは難しいが、よく言われるのは以下の三種類の分類である。</p>
<ol style="list-style-type: decimal">
<li>教師あり学習</li>
<li>教師なし学習</li>
<li>強化学習</li>
</ol>
<p><strong>教師あり学習(Supervised Learning)</strong> とは、「問題と解答のセット」を与えて、それで学習させる方法である。例えば、予め大量の写真を用意し、それぞれに「ネコ」や「イヌ」といったラベルをつけておく。それを学習させることで、「学習に用いたデータセットに含まれていない、初めて見る写真」に対しても正しく「ネコ」や「イヌ」と判定できるようにさせるのが典型的な教師あり学習である。</p>
<p><strong>教師なし学習(Unsupervised Learning)</strong> とは、データだけを与えて、データを分類したり、似ているものを探したりさせる方法である。例えば物品の売上データを解析し、「ある商品Aを購入した人は、次は商品Bを購入する可能性が高い」といった関係を見つければ、商品Aを購入した人に「Bはいかがでしょうか？」と勧めることができ、売上向上につながる。オンラインショップなどでよく見る「この商品を買った人はこんな商品も買っています」というアレである。</p>
<p><strong>強化学習(Reinforcement Learning)</strong> とは、何かエージェントに行動をさせて、その結果として報酬を与えることで、「うまく」行動できるように学習させていく手法である。典型的な応用例はチェスや囲碁、将棋などのボードゲームのAIであろう。ある局面において、多数ある合法手の中から「次の一手」を選ばなければならない。この時、とりあえず(現在の知識で)適当に指してみて、勝負が決まってから振り返り、「最終的に勝利につながった手」に正の報酬を、「敗北につながった手」に負の報酬を与えることで、それぞれの局面において「これは良い手だった」「これは悪手だった」と学習していく。</p>
<p>これらはどれも面白く、それぞれ奥が深いのだが、本章では教師あり学習を学ぶ。</p>
<p>「教師あり学習」が扱う問題は、さらに「分類」と「回帰」にわけることができる。分類とは、入力に対して有限のラベルのどれかを当てる問題である。例えば「ネコ」「イヌ」「ゾウ」「パンダ」のどれかが写っている写真を見せられ、何が写っているかを答えるのが典型的な分類問題である。特に、ラベルが「Yes」か「No」の二種類である時、これを二値分類問題と呼ぶ。回帰問題とは、入力に対して何か連続な値を返す問題である。例えば家の広さ、築年数、駅からの距離や周りの条件等から家賃を推定するのが典型的な回帰問題である。</p>
<h3 id="学習と最適化">学習と最適化</h3>
<p>機械学習では、よく「学習」という言葉が出てくる。学習とは、ある量を最適化することだ。その最適化の簡単な例として、線形回帰を見てよう。</p>
<p>回帰とは、何かしらの入力<span class="math inline">\(x\)</span>に対して、出力<span class="math inline">\(y\)</span>が得られる時、その間の関係<span class="math inline">\(y = f(x)\)</span>を推定する問題である。例えば片方を固定されたバネに荷重をかけ、どのくらい伸びるかを調べる実験を考える。この場合の入力<span class="math inline">\(x\)</span>は荷重、出力<span class="math inline">\(y\)</span>はバネの伸びである。とりあえずいくつか重りを乗せてみて、荷重と伸びの観測値をグラフにプロットしてみたら以下のようになったとしよう。</p>
<div class="figure">
<img src="fig/regression.png" alt="バネの伸びと荷重の関係" />
<p class="caption">バネの伸びと荷重の関係</p>
</div>
<p>ここから、バネ定数を推定するには最小二乗法を使えば良いことは知っているであろうが、簡単におさらいしておこう。いま、<span class="math inline">\(N\)</span>回異なる荷重をかける実験を行い、荷重とバネの伸びの観測値の組<span class="math inline">\((x_i, y_i)\)</span>が得られたとする。さて、フックの法則から<span class="math inline">\(y = a x\)</span>が予想される。<span class="math inline">\(x_i\)</span>の荷重がかかった時、このモデルによる予想値は<span class="math inline">\(a x_i\)</span>だが、観測値は<span class="math inline">\(y_i\)</span>だ。そのズレ<span class="math inline">\(y_i - a x_i\)</span>を残差と呼ぶ。この残差の二乗和は<span class="math inline">\(a\)</span>の関数であり、以下のように表すことができる。</p>
<p><span class="math display">\[
C(a) = \sum_i^N (a x_i - y_i)^2
\]</span></p>
<p><span class="math inline">\(C(a)\)</span>はモデルと観測値の誤差を表している。<span class="math inline">\(a\)</span>が大きすぎても小さすぎても<span class="math inline">\(C(a)\)</span>は大きくなるので、どこかに最適な<span class="math inline">\(a\)</span>があるだろう。<span class="math inline">\(C(a)\)</span>を最小化するような<span class="math inline">\(a\)</span>の値は、<span class="math inline">\(C(a)\)</span>を<span class="math inline">\(a\)</span>で微分してゼロになるような点であるはずだ。微分してみよう。</p>
<p><span class="math display">\[
\frac{dC}{da} = \sum_i^N (2 a x_i^2 - 2a x_i y_i) = 0
\]</span></p>
<p>これを<span class="math inline">\(a\)</span>について解けば、</p>
<p><span class="math display">\[
a = \frac{\sum_i^N x_i y_i}{\sum_i^N x_i^2}
\]</span></p>
<p>を得る。さて、実はこれは最も単純な機械学習の例となっている。</p>
<p>我々は、<span class="math inline">\(y = a x\)</span>というモデルを仮定し、<span class="math inline">\(N\)</span>個の観測値の組<span class="math inline">\((x_i, y_i)\)</span>を使ってモデルパラメータ<span class="math inline">\(a\)</span>を決定した。このパラメータを決定するプロセスを「学習」と呼ぶ。「学習」では、<span class="math inline">\(C(a)\)</span>を最小化するようにモデルのパラメータ<span class="math inline">\(a\)</span>を決定した。この最小化する関数を <strong>目的関数 (Cost Function)</strong>と呼ぶ。目的関数を最小化するために使われた観測データを「トレーニングデータ」と呼ぶ。トレーニングデータに対する誤差を<strong>訓練誤差</strong>と呼ぶ。</p>
<div class="figure">
<img src="fig/error.png" alt="訓練誤差と汎化誤差" />
<p class="caption">訓練誤差と汎化誤差</p>
</div>
<p>さて、我々の目的はあくまで「バネの伸び」という物理現象を記述することであって、「観測データを再現するモデルの構築」は、その手段に過ぎなかった。したがって、こうして得られた<span class="math inline">\(y = ax\)</span>というモデルは、未知の入力<span class="math inline">\(x\)</span>に対して、良い予想値<span class="math inline">\(y\)</span>を与えなくてはならない。トレーニングデータに含まれない入力<span class="math inline">\(x\)</span>に対して、我々が構築したモデルがどれくらい良いかを調べることを「テスト」と呼ぶ。</p>
<p>具体的には、モデルを決める時に使ったトレーニングデータとは別のデータセットを用意しておき、そのデータについてモデルがどれくらいよく予想できるかを確認する、ということがよく行われる。このような目的に使われるデータを「テストデータ」と呼び、テストデータに対する誤差を<strong>汎化誤差</strong>と呼ぶ。</p>
<p>訓練誤差は小さいのに、汎化誤差が大きい場合、トレーニングデータに最適化され過ぎており、応用が効かない「頭でっかち」なモデルになっていることを示唆する。これを <strong>過学習(overfitting)</strong> と呼ぶ。データの数に比べてモデルパラメータが多い時によく起きる。</p>
<div class="figure">
<img src="fig/overfitting.png" alt="訓練誤差・汎化誤差・過学習" />
<p class="caption">訓練誤差・汎化誤差・過学習</p>
</div>
<p>今回の講義で用いるTensorFlowをはじめとして、機械学習は高度に完成されたライブラリやフレームワークが多数存在する。その内部で用いられている理論やアルゴリズムは難しいものが多く、それらのフレームワークを「ブラックボックス」として用いるのはある程度やむを得ないところもある。しかし、機械学習に限らないことだが、基本的な概念、用語については、簡単な例でしっかり理解しておいた方が良い。「機械学習は最小二乗法のお化けのようなものだ」というと語弊があるのだが、学習、目的関数、訓練誤差、汎化誤差、過学習といった機械学習で頻出する単語のイメージを、中身がよくわかる単純な例、例えば線形モデルの最小二乗法で理解しておく、ということは非常に重要なことである。</p>
<p>機械学習に限らないことだが、「何かよくわからない概念が出てきたら、簡単な例で考えてみる」癖をつけておきたい。</p>
<h2 id="重回帰分析">重回帰分析</h2>
<p>回帰とは、何か入力から出力を予想することである。入力となる変数を説明変数、予想したい出力を目的変数と呼ぶ。例えば、ある人の「賃金」を予想したいとしよう。日本は(まだ)年功序列を採用している会社が多いため、年齢が増えるほど賃金が増えると期待される。そこで、年齢を説明変数、賃金を目的変数に取ってみよう。予想の仕方だが、もっとも簡単には、年齢を<span class="math inline">\(x\)</span>、賃金を<span class="math inline">\(y\)</span>として、</p>
<p><span class="math display">\[
y = a x + b
\]</span></p>
<p>と線形の関係を仮定したくなる。このような形による回帰を線形回帰と呼ぶ。また、説明変数が一つしかない場合を単回帰分析と呼ぶ。しかし、賃金を決める要因は他にもある。例えば学歴や、企業規模も関係するであろう。そこで、年齢だけでなく、学歴や企業規模も含めて賃金を予想したい。このように、複数の説明変数から目的変数を予想することを重回帰分析と呼ぶ。説明変数が<span class="math inline">\(x_1, x_2, \cdots\)</span>とある時、重回帰分析では目的変数は説明変数を使って</p>
<p><span class="math display">\[
y = a_1 x_1 + a_2 x_2 + \cdots + b
\]</span></p>
<p>と予想される。</p>
<p>さて、年齢のような変数ならこれで良いが、学歴を説明変数にするにはどうすればよいだろうか？先のように式に落とすためには、なんらかの方法で学歴を数値化しなければならない。この時、ラベルごとに「ダミー変数」と呼ばれる変数を使うことがよく行われる。ダミー変数とは、ある条件を満たしている時に1、そうでない時に0となるような変数である。</p>
<p>例えば、大学卒であるかないかが賃金に与える影響を重回帰分析したいとしよう。この時、年齢を<span class="math inline">\(x\)</span>、大学卒であるかどうかのダミー変数を<span class="math inline">\(z\)</span>として、賃金<span class="math inline">\(y\)</span>を</p>
<p><span class="math display">\[
y = a x + c z + b
\]</span></p>
<p>と予想する。<span class="math inline">\(z\)</span>は大卒であるときに<span class="math inline">\(1\)</span>、そうで無い時に<span class="math inline">\(0\)</span>となる。すなわち、係数<span class="math inline">\(c\)</span>は「大卒」であるときに期待される賃金の増加分と解釈できる。ラベルが複数ある時、例えば学歴を「中卒」「高卒」「大卒」に区別したい時には、ダミー変数を<span class="math inline">\(z_1\)</span>、<span class="math inline">\(z_2\)</span>、<span class="math inline">\(z_3\)</span>と三つ用意し、中卒の時には<span class="math inline">\(z_1 = 1, z_2 = 0, z_3 = 0\)</span>、高卒の時には<span class="math inline">\(z_1 = 0, z_2 = 1, z_3 = 0\)</span>などとすることで学歴を変数として表現することができる。課題では、学歴に加えて企業規模が賃金に与える影響も重回帰分析で調べてみよう。</p>
<h2 id="ganとは">GANとは</h2>
<p>通常よく使われる機械学習、例えば「植物の写真を見せて名前を答えるモデル」や「人間の写真を見せて年齢を推定するモデル」などでは、モデルは入力となるデータに対して何かしら「答え」を返すことが目的である。しかし、そういう分類や回帰ができるようになってくると、もっと難しい作業、例えば「有名な画家の絵を多数模写させることで、その画家のタッチでオリジナルの絵が書けるモデル」や、「テーマを伝えただけで映画やドラマの脚本を書けるモデル」などをやらせてみたくなるのが人情である。ここではそんな例として、GANを取り上げる。GAN (Generative Adversarial Networks)とは、直訳すると「敵対的生成ネットワーク」であり、二つのモデルを競わせることで画像を生成する手法である。</p>
<p>GANでは、GeneratorとDiscriminatorの二つのモデルを用意する。これらはよく「偽造者」「鑑定者」に例えられる。まず、本物のデータセット(例えば有名な画家の絵)を用意する。その後、ランダムに「本物のデータ」と「偽造者」が生成した「偽物のデータ」を「鑑定士」に見せ、それを本物か、偽物か判定させる。鑑定者から見れば、これは二値分類問題になっている。ラベルは「本物」か「偽物」である。鑑定者は大量に見せられるデータをどんどん鑑定することで「鑑定士」としての観察眼を磨いていく。</p>
<p>逆に、偽造者は、自分が提出したデータが「偽物」と見破られたら失敗、「本物」と鑑定されたら成功であり、そのフィードバックを受けながら「偽造者」としての腕を磨いていく。</p>
<div class="figure">
<img src="fig/gan.png" alt="GANの概念図" />
<p class="caption">GANの概念図</p>
</div>
<p>こうして「偽造者」と「鑑定者」がお互いに切磋琢磨しながら学習していくと、最終的に「本物と見紛うばかりのデータを生成できる偽造者が誕生するだろう」というのがGANの要諦である。今回の課題では、適当なデータセットを用意し、偽造者と鑑定者を学習させることで、最終的に偽造者が用意したデータセットを真似た絵を生成できるようになるプロセスを観察しよう。</p>
<h2 id="簡単な機械学習課題">簡単な機械学習：課題</h2>
<h3 id="課題1重回帰分析">課題1：重回帰分析</h3>
<p>年齢や学歴が給与に与える影響を重回帰分析で調べて見よう。なお、データは<a href="https://www.mhlw.go.jp/toukei/itiran/roudou/chingin/kouzou/z2018/index.html">厚生労働省の平成30年賃金構造基本統計調査</a>による。</p>
<p>新しいノートブックを開き<code>salary.ipynb</code>として保存せよ。</p>
<h4 id="ライブラリのインポート">1. ライブラリのインポート</h4>
<p>最初にライブラリのインポートをしておこう。</p>
<div class="sourceCode"><pre class="sourceCode py"><code class="sourceCode python"><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt
<span class="im">import</span> pandas <span class="im">as</span> pd
<span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</code></pre></div>
<h4 id="給与データのダウンロード">2. 給与データのダウンロード</h4>
<p>次に、給与データ(CSVファイル)をダウンロードしよう。</p>
<div class="sourceCode"><pre class="sourceCode py"><code class="sourceCode python"><span class="op">!</span>wget https:<span class="op">//</span>kaityo256.github.io<span class="op">/</span>python_zero<span class="op">/</span>gan<span class="op">/</span>salary.csv</code></pre></div>
<h4 id="データの読み込み">3. データの読み込み</h4>
<p>CSVファイルをPandasで読み込んで見よう。</p>
<div class="sourceCode"><pre class="sourceCode py"><code class="sourceCode python">df <span class="op">=</span> pd.read_csv(<span class="st">&quot;salary.csv&quot;</span>)
df</code></pre></div>
<p><code>age</code>や<code>education</code>、<code>company_size</code>、<code>salary</code>といったデータが読み込まれたはずだ。これらはそれぞれ年齢、学歴、企業規模、給与(千円)である。学歴と企業規模のラベルはそれぞれ以下の通り。</p>
<ul>
<li>学歴(<code>education</code>)</li>
<li><code>middle</code>: 中卒</li>
<li><code>high</code>: 高卒</li>
<li><code>tech</code>: 高専・短大卒</li>
<li><code>university</code>: 大学・大学院卒</li>
<li>企業規模(<code>company_size</code>)</li>
<li><code>small</code>: 小企業(従業員数10〜99人)</li>
<li><code>medium</code>: 中企業(従業員数100〜999人)</li>
<li><code>large</code>: 大企業(従業員数1000人以上)</li>
</ul>
<h4 id="大企業のみのデータ">4. 大企業のみのデータ</h4>
<p>後でプロットするため、大企業のみのデータを抽出しよう。</p>
<div class="sourceCode"><pre class="sourceCode py"><code class="sourceCode python">large <span class="op">=</span> df[df[<span class="st">&#39;company_size&#39;</span>] <span class="op">==</span> <span class="st">&#39;large&#39;</span>]
large</code></pre></div>
<p><code>company_size</code>が<code>large</code>のデータのみが抽出されたはずだ。</p>
<h4 id="データのピボット">5. データのピボット</h4>
<p>学歴別の収入を見るため、年齢を行、学歴を列とした二次元のデータに整形しよう。</p>
<div class="sourceCode"><pre class="sourceCode py"><code class="sourceCode python">large <span class="op">=</span> large.pivot(index<span class="op">=</span><span class="st">&#39;age&#39;</span>, columns<span class="op">=</span><span class="st">&#39;education&#39;</span>, values<span class="op">=</span><span class="st">&#39;salary&#39;</span>)
large</code></pre></div>
<p>それぞれの年齢に対して、学歴別に収入が並んだデータになったはずである。</p>
<h4 id="データのプロット">6. データのプロット</h4>
<p>大企業に務める人の収入を学歴別にプロットしてみよう。</p>
<div class="sourceCode"><pre class="sourceCode py"><code class="sourceCode python">large.plot()</code></pre></div>
<p>年齢を横軸とし、学歴別に賃金(月収、単位千円)がプロットされたはずだ。</p>
<h4 id="回帰用データの作成">7. 回帰用データの作成</h4>
<p>先程のデータを見ると、55歳を超えると賃金が下がるのがわかる。これでは線形近似がしづらいので、55歳以下のデータに限定してフィッティングすることにしよう。</p>
<div class="sourceCode"><pre class="sourceCode py"><code class="sourceCode python">df <span class="op">=</span> df[df[<span class="st">&#39;age&#39;</span>] <span class="op">&lt;</span> <span class="dv">55</span>]
inputs <span class="op">=</span> df.drop(<span class="st">&#39;salary&#39;</span>, axis<span class="op">=</span><span class="dv">1</span>)
inputs</code></pre></div>
<p>年齢が55歳以下のデータのみを抽出した後、説明変数として<code>salary</code>以外のデータを<code>input</code>として取得している。年齢(<code>age</code>)、最終学歴(<code>education</code>)、企業規模(<code>company_size</code>)が並んだはずだ。これらから給与(<code>salary</code>)を推定するのが今回の目的である。</p>
<h4 id="ダミー変数の作成">8. ダミー変数の作成</h4>
<p>現在、企業規模が<code>small</code>、<code>medium</code>、<code>large</code>と「ラベル」になっている。これを「数値」にしないとフィッティングができない。そこで、これらのラベルをダミー変数に変換しよう。Pandasは<code>get_dummies</code>という命令一発でダミー変数に変換することができる。</p>
<div class="sourceCode"><pre class="sourceCode py"><code class="sourceCode python">inputs <span class="op">=</span> pd.get_dummies(inputs)
inputs</code></pre></div>
<p>学歴を表すために、<code>education_middle</code>や<code>education_high</code>といったダミー変数が導入された。例えば最終学歴(<code>education</code>)が高卒(<code>high</code>)だった場合は<code>education_high=1</code>、大学・大学院卒なら<code>education_university=1</code>(それ以外の<code>education</code>由来のダミー変数はゼロ)といった具合である。</p>
<h4 id="重回帰分析-1">9. 重回帰分析</h4>
<p>ではこのデータを重回帰分析してみよう。といっても、scikit-learnの線形回帰の<code>fit</code>関数を呼ぶだけだ。</p>
<div class="sourceCode"><pre class="sourceCode py"><code class="sourceCode python">lr <span class="op">=</span> LinearRegression()
lr.fit(inputs.values,df[<span class="st">&#39;salary&#39;</span>])</code></pre></div>
<h4 id="係数の表示">10. 係数の表示</h4>
<p>決定された回帰係数を表示してみよう。以下を実行せよ。</p>
<div class="sourceCode"><pre class="sourceCode py"><code class="sourceCode python">labels <span class="op">=</span> inputs.columns
pd.DataFrame({<span class="st">&quot;Name&quot;</span>:labels, <span class="st">&quot;Coefficients&quot;</span>: lr.coef_})</code></pre></div>
<p>それぞれのラベル(例えば<code>education_high</code>)に対して、係数(<code>Coefficents</code>)が表示されたはずだ。このうち、年齢(<code>age</code>)は「年齢が一つ増える毎に、どれだけ賃金が増えるか(単位：千円)」を表している。ダミー変数は、例えば「高卒である」ならば、<code>education_high</code>に対応する賃金が増加(マイナスなら減少)することを表している。</p>
<p>このデータを見て、中卒と大卒で賃金がどれだけ変わるか計算せよ。大企業と小企業ではどうか？</p>
<h4 id="フィッティング結果のプロット">11.フィッティング結果のプロット</h4>
<p>せっかく回帰分析により「年齢」「学歴」「企業規模」から賃金が予想できるようになったはずなので、予想結果を実際のデータに重ねてプロットしてみよう。以下を実行せよ。</p>
<div class="sourceCode"><pre class="sourceCode py"><code class="sourceCode python">dic <span class="op">=</span> <span class="bu">dict</span>(<span class="bu">zip</span>(labels, lr.coef_))
X <span class="op">=</span> [i <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">22</span>,<span class="dv">55</span>)]
a <span class="op">=</span> dic[<span class="st">&quot;age&quot;</span>]
e1 <span class="op">=</span> dic[<span class="st">&quot;education_university&quot;</span>]
e2 <span class="op">=</span> dic[<span class="st">&quot;education_middle&quot;</span>]
s <span class="op">=</span> dic[<span class="st">&quot;company_size_large&quot;</span>]
c <span class="op">=</span> lr.intercept_
Y1 <span class="op">=</span> [x <span class="op">*</span> a <span class="op">+</span> e1 <span class="op">+</span> s <span class="op">+</span> c <span class="cf">for</span> x <span class="kw">in</span> X]
Y2 <span class="op">=</span> [x <span class="op">*</span> a <span class="op">+</span> e2 <span class="op">+</span> s <span class="op">+</span> c <span class="cf">for</span> x <span class="kw">in</span> X]
ax <span class="op">=</span> large.plot()
ax.plot(X,Y1, marker<span class="op">=</span><span class="st">&#39;o&#39;</span>)
ax.plot(X,Y2, marker<span class="op">=</span><span class="st">&#39;*&#39;</span>)</code></pre></div>
<p>正しく実行されていれば、大企業に務める人の賃金のグラフに、回帰による予測値(中卒と大学・大学院卒)が重ねてプロットされたはずである。どのくらい正確に予想できているだろうか？もし実際のデータとずれているなら、その原因は何か考察せよ。</p>
<h3 id="課題2gan">課題2：GAN</h3>
<p>敵対的生成ネットワーク、GAN (Generative Adversarial Networks)を体験してみよう。これは、偽造者(Generator)と鑑定者(Discriminator)がお互いに切磋琢磨させることで、偽造者に本物そっくりの画像を生成させるようにする手法である。</p>
<p>新しいノートブックを開き<code>gan.ipynb</code>として保存せよ。</p>
<p><strong>注意</strong>：以下のコードは古いTensorFlowでしか動作しないため、書き直す予定です。</p>
<h4 id="tensorflowのインストール">1. TensorFlowのインストール</h4>
<p>Google ColabではデフォルトでTensorFlowが使えるが、今回はやや古いバージョンを使いたいので、バージョンを指定してインストールをする。</p>
<div class="sourceCode"><pre class="sourceCode py"><code class="sourceCode python"><span class="op">%</span>tensorflow_version <span class="fl">1.</span>x
<span class="op">!</span>pip install tensorflow<span class="op">==</span><span class="fl">1.13</span>.<span class="dv">1</span></code></pre></div>
<p>最初の<code>%</code>から始まる行はマジックコメントと呼ばれ、Google Colabに「これからバージョン1.0系を使うよ」という指示をする。</p>
<pre class="txt"><code>Successfully installed mock-3.0.5 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0</code></pre>
<p>と表示されれば正しくインストールされている。</p>
<h4 id="サンプルプログラムのダウンロード">2. サンプルプログラムのダウンロード</h4>
<p>GANのプログラムは、簡単なものでもそれなりに長いコードを記述する必要がある。今回は既に入力されたプログラムをダウンロードしよう。以下を実行せよ。</p>
<div class="sourceCode"><pre class="sourceCode py"><code class="sourceCode python"><span class="op">!</span>wget https:<span class="op">//</span>kaityo256.github.io<span class="op">/</span>python_zero<span class="op">/</span>gan<span class="op">/</span>gan_test.py</code></pre></div>
<p><code>‘gan_test.py’ saved</code>と表示されればダウンロード完了である。</p>
<h4 id="インポート">3. インポート</h4>
<p>先程ダウンロードしたプログラムをインポートしよう。</p>
<div class="sourceCode"><pre class="sourceCode py"><code class="sourceCode python"><span class="im">import</span> gan_test</code></pre></div>
<p>実行時に多数の<code>FutureWarning</code>が出るが、気にしなくて良い。これでGANが使えるようになった。</p>
<h4 id="データのダウンロード">4. データのダウンロード</h4>
<p>GANでは、まず「正解の画像」をデータセットとして与える必要がある。偽造者は、その画像に似せて絵を描いていく。逆に、与えるデータによって「好きな画家」を模写できるように学習させることができる。本講義では、三つのデータセットを用意した。</p>
<ul>
<li><code>mnist.tfrecord</code> 手書きの数字(MNIST)</li>
<li><code>fontawesome.tfrecord</code> Font Awesomeというフォントのシンボルアイコン10種類</li>
<li><code>hiragana.tfrecord</code> ひらがなすべて(IPAゴシックフォント)</li>
</ul>
<p>上記のうち、好きなものを一つ選んで<code>TRAIN_DATA</code>とし、ダウンロードすること。数字は学習が容易だが、ひらがなは難しく、シンボルはその中間、といった特徴がある。</p>
<p>以下は手書きの数字(MNIST)を選んだ場合の例である。</p>
<div class="sourceCode"><pre class="sourceCode py"><code class="sourceCode python">TRAIN_DATA <span class="op">=</span> <span class="st">&quot;mnist.tfrecord&quot;</span>
url<span class="op">=</span><span class="st">&quot;https://kaityo256.github.io/python_zero/gan/&quot;</span>
<span class="bu">file</span><span class="op">=</span>url<span class="op">+</span>TRAIN_DATA
<span class="op">!</span>wget $file</code></pre></div>
<p><code>‘mnist.tfrecord’ saved</code>など、自分が選んだファイル名が表示されればダウンロード完了である。</p>
<h4 id="ganの実行">5. GANの実行</h4>
<p>ではいよいよGANの実行をしてみよう。以下を実行せよ。</p>
<div class="sourceCode"><pre class="sourceCode py"><code class="sourceCode python">gan_test.run_gan(TRAIN_DATA)</code></pre></div>
<p>最初に</p>
<pre class="txt"><code>WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.</code></pre>
<p>といった警告が出るが、気にしないで良い。</p>
<p>画面には、数十秒ごとに偽造者が作成した画像が表示されていく。最初は完全なノイズにしか見えなかった画像が、学習が進むにつれて偽造者が「腕を上げていく」様子が見えるであろう。学習が終わったら(もしくは途中で止めて)、別の画像でも学習させてみよ。</p>
<h2 id="余談aiに悪意はあるか">余談：AIに悪意はあるか</h2>
<p>AIに意識があるか、という問題は難しい。個人的には「AIはそのうち意識を持つ」と信じているが、現時点では「まだソフトウェアなんだな」と思う時と「人間と同じ問題を抱えているのでは」と思う時の両方がある。</p>
<p>「あ、AIはただのソフトウェアなんだな」と思う例の一つは画像認識である。「犬」「猫」「羊」などのラベルがついた画像を事前に学習させておくことで、写真に何が写っているかを認識するAIを作るものだ。一見するとこのAIは写真に写るものを正しく認識しているように見えるが、何もいない草原に「羊がいる」と判断してしまう。「羊」のラベルがついた画像のほとんどが草原であったため、「草原＝羊」と認識してしまったのだ。同様な例に「ハスキーと狼問題」がある。シベリアン・ハスキーは狼に似た犬種であるが、そのハスキーと狼を見分けるAIを作ったところ、実は犬ではなく「背景に雪があるかどうか」で判断していることがあった。</p>
<p>多くの場合、こうした画像認識の失敗は笑い話で済むが、差別問題がからむとやっかいなことになる。2015年、Googleは、写真管理アプリGoogle Photosをリリースしたが、そのアプリには写真に写っているものを認識し、ラベル付けする機能があった。しかし、黒人女性が写る写真に「ゴリラ」とタグ付けしてしまい、Googleが謝罪する事態となった。これについては「差別的な人間が黒人に『ゴリラ』という差別的なタグをつけていたものを学習したせいだ」という噂も流れたが、どうやら純粋に「白人以外」のデータが足りずに、素で間違ったようだ。他にも、やはり黒人女性を「猿(Apes)」と認識してしまうことがわかった。結局Googleは根本解決ができず、「ゴリラ、猿、チンパンジー」といったラベルを禁止ワードにすることで対処することになった。</p>
<p>Google翻訳がジェンダーバイアスを持つことも知られている。例えば現時点(2019年12月4日現在)では、「<strong>医者</strong> は旅行先でカバンを忘れてきた。」は「The doctor has forgotten <strong>his</strong> bag at the travel destination.」と訳すが、「<strong>看護師</strong> は旅行先で……」とすると「The nurse has forgotten <strong>her</strong> bag when traveling.」と訳す。Google翻訳は多くの翻訳例を通じて学習したモデルを用いているが、そのデータ上で「Docter」が「his」と、「Nurse」が「her」と一緒に用いらていれることが多かったのだと思われる。</p>
<p>Google Photosの問題は「学習データに白人が多く黒人が少なかったため」に起きたことであり、Google翻訳の問題は学習用データを通じて「医者は男性が多く、看護師は女性が多い」という「偏見」も一緒に学習してしまったために起きたことだ。現時点では「AI」に罪はなく、「AIの学習過程で人間持つの差別や偏見が注入された」と認識されているが、そもそも学習で偏った情報に触れて偏見を身につけてしまうという過程は人間と全く同じである。既に自らの過ちをAIのせいにしている人も出現しており、そのうちAIが高度に発展した場合、我々はAIそのものに悪意や偏見を感じるようになるのかもしれない。</p>
<ul>
<li>「Notes on AI Bias」<a href="https://www.ben-evans.com/benedictevans/2019/4/15/notes-on-ai-bias" class="uri">https://www.ben-evans.com/benedictevans/2019/4/15/notes-on-ai-bias</a></li>
</ul>
</article>
</body>
</html>
